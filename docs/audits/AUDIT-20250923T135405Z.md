# VelaNova Audit — 20250923T135405Z (UTC)

- Base: /home/pudding/Projects/VelaNova
- Host: Linux pop-os 6.16.3-76061603-generic #202508231538~1757385336~22.04~8f363f2 SMP PREEMPT_DYNAMIC Tue S x86_64 x86_64 x86_64 GNU/Linux
- User: pudding


## OS / Kernel / GPU / Tooling

```
OS:
No LSB modules are available.
Distributor ID:	Pop
Description:	Pop!_OS 22.04 LTS
Release:	22.04
Codename:	jammy

Kernel:
Linux 6.16.3-76061603-generic

GPU:
GPU 0: NVIDIA GeForce RTX 2070 with Max-Q Design (UUID: GPU-e03951aa-f813-5ebe-a5a0-bc071e39b32e)
name, driver_version, memory.total [MiB]
NVIDIA GeForce RTX 2070 with Max-Q Design, 570.172.08, 8192 MiB

Python:
Python 3.10.12

Docker:
Docker version 27.5.1, build 27.5.1-0ubuntu3~22.04.2
Docker Compose version v2.39.2

NVIDIA Container Toolkit:
cli-version: 1.12.1
lib-version: 1.12.1
build date: 2023-03-21T16:54+00:00
build revision: 41335937dcf88680b29dca7d23b4102c2d2f2f2f
build compiler: x86_64-linux-gnu-gcc-9 11.2.0
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -fPIC -Wdate-time -D_FORTIFY_SOURCE=2 -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fplan9-extensions -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -fPIC -g -O2 -fdebug-prefix-map=/home/jenkins/workspace/pop-os/repos/_build/ci/git/libnvidia-container/d17aa6f4960e1d386abadf2288403efa4c1753ab/jammy/partial.source/archive=. -fstack-protector-strong -Wformat -Werror=format-security -I/usr/include/tirpc -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections -Wl,-Bsymbolic-functions -Wl,-z,relro
```


## Project tree (depth 3)

```
/home/pudding/Projects/VelaNova
├── compose
│   ├── data
│   │   └── open-webui
│   ├── docker-compose.yml
│   └── docker-compose.yml.bak
├── config
│   ├── settings.yaml
│   └── voice.yaml
├── docs
│   ├── audits
│   │   ├── AUDIT-20250917T173921Z.md
│   │   ├── AUDIT-20250917T174322Z.md
│   │   ├── AUDIT-20250917T175130Z.md
│   │   ├── AUDIT-20250917T191059Z.md
│   │   ├── AUDIT-20250918T103939Z.md
│   │   ├── AUDIT-20250918T104303Z.md
│   │   ├── AUDIT-20250919T103941Z.md
│   │   ├── AUDIT-20250921T094932Z.md
│   │   └── AUDIT-20250923T135405Z.md
│   ├── IMPLEMENTATION_PLAN.md
│   ├── INSTRUCTIONS.md
│   ├── OPERATIONS.md
│   ├── PHASE_A_ACCEPTANCE.md
│   ├── PHASE_A_ACCEPTANCE.md.20250917T191059Z.bak
│   ├── PHASE_B_ACCEPTANCE.md
│   ├── PHASE_C_ACCEPTANCE.md
│   ├── PHASE_C_COMPLETION.md
│   ├── PHASE_C_PROOF_20250919.txt
│   ├── PHASE_D_ACCEPTANCE.md
│   ├── Phase E Completion (Dev Mode).md
│   └── SNAPSHOTS.md
├── logs
│   ├── last_output.wav
│   ├── mic_probe.wav
│   ├── tts_smoke.wav
│   ├── voice_loop-20250915.log
│   ├── voice_loop-20250916.log
│   ├── voice_loop-20250917.log
│   ├── voice_loop-20250918.log
│   ├── voice_loop-20250919.log
│   ├── voice_loop-20250919.log.1
│   ├── voice_loop-20250919.log.2
│   ├── voice_loop-20250919.log.3
│   ├── voice_loop-20250919.log.4
│   ├── voice_loop-20250919.log.5
│   ├── voice_loop-20250919.log.6
│   ├── voice_loop-20250919.log.7
│   ├── voice_loop-20250921.log
│   └── voice_loop-20250923.log
├── memory
│   ├── db
│   │   └── memory.sqlite
│   ├── docs
│   ├── index
│   ├── logs
│   └── tmp
├── models
│   ├── ollama
│   │   ├── id_ed25519
│   │   ├── id_ed25519.pub
│   │   └── models
│   ├── oww
│   ├── piper
│   │   └── en
│   ├── wake
│   │   ├── alexa_v0.1.tflite
│   │   ├── embedding_model.tflite
│   │   ├── hey_jarvis_v0.1.tflite
│   │   ├── hey_mycroft_v0.1.tflite
│   │   ├── hey_rhasspy_v0.1.tflite
│   │   ├── melspectrogram.tflite
│   │   ├── timer_v0.1.tflite
│   │   └── weather_v0.1.tflite
│   └── whisper
│       └── small
├── orchestrator
│   ├── check_env.py
│   ├── memory_selftest.py
│   ├── memory_store.py
│   ├── mic_probe.py
│   ├── __pycache__
│   │   ├── memory_store.cpython-310.pyc
│   │   └── voice_loop.cpython-310.pyc
│   └── voice_loop.py
└── tools
    └── audit.sh

25 directories, 61 files
```


## Key files present

```
[OK] orchestrator/voice_loop.py (33651 bytes)
[OK] config/settings.yaml (2407 bytes)
[OK] compose/docker-compose.yml (727 bytes)
[OK] docs/SNAPSHOTS.md (1643 bytes)
```


## Python virtualenv packages (.venv)

```
Python 3.10.12
ctranslate2        4.6.0
faster-whisper     1.2.0
onnxruntime        1.16.3
openwakeword       0.6.0
piper-tts          1.3.0
scipy              1.15.3
sounddevice        0.5.2
soundfile          0.13.1
```


## Listening ports (Jarvis-related)

```
LISTEN 0      4096         0.0.0.0:11434      0.0.0.0:*                                         
LISTEN 0      4096         0.0.0.0:3000       0.0.0.0:*                                         
LISTEN 0      4096            [::]:11434         [::]:*                                         
LISTEN 0      4096            [::]:3000          [::]:*                                         
```


## Docker Compose status

```
NAME          IMAGE                                  COMMAND               SERVICE      CREATED      STATUS                PORTS
vela_ollama   ollama/ollama:0.3.13                   "/bin/ollama serve"   ollama       6 days ago   Up 6 days             0.0.0.0:11434->11434/tcp, [::]:11434->11434/tcp
vela_webui    ghcr.io/open-webui/open-webui:latest   "bash start.sh"       open-webui   6 days ago   Up 6 days (healthy)   0.0.0.0:3000->8080/tcp, [::]:3000->8080/tcp
```


## Ollama models available

```
```


## Audio devices (ALSA/Pulse)

```
**** List of CAPTURE Hardware Devices ****
card 0: PCH [HDA Intel PCH], device 0: ALC295 Analog [ALC295 Analog]
  Subdevices: 1/1
  Subdevice #0: subdevice #0

49	alsa_output.pci-0000_00_1f.3.analog-stereo.monitor	PipeWire	s32le 2ch 48000Hz	RUNNING
50	alsa_input.pci-0000_00_1f.3.analog-stereo	PipeWire	s32le 2ch 48000Hz	SUSPENDED
```


## Latest orchestrator logs

```
Showing: /home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log
2025-09-23 09:20:32,058 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log", "time": "2025-09-23T09:20:32"}
2025-09-23 09:20:32,059 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-23 09:20:32,059 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-23 09:20:33,438 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-23 09:20:33,445 [INFO] memory_doc {"doc_id": "a619b442b25546af98523afc0d21718a"}
2025-09-23 09:20:33,445 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-23 09:20:33,446 [INFO] await_wake {"mode": "text"}
2025-09-23 09:20:45,084 [INFO] heard_text {"text": "VelaNova, store this fact: the codeword is mango-73."}
2025-09-23 09:20:45,084 [INFO] wake_detected {"via": "text", "heard": "VelaNova, store this fact: the codeword is mango-73."}
2025-09-23 09:20:45,086 [INFO] wake_remainder {"text": ", store this fact: the codeword is mango-73."}
2025-09-23 09:20:45,086 [INFO] user_text_prefill {"text": ", store this fact: the codeword is mango-73."}
2025-09-23 09:20:45,103 [INFO] store_codeword {"token": "mango-73"}
2025-09-23 09:20:45,103 [INFO] tts_start {}
2025-09-23 09:20:48,276 [INFO] tts_synth {"engine": "piper", "dur_ms": 3173}
2025-09-23 09:20:49,863 [INFO] await_wake {"mode": "text"}
2025-09-23 09:21:28,543 [INFO] heard_text {"text": "VelaNova, what is the codeword?"}
2025-09-23 09:21:28,543 [INFO] wake_detected {"via": "text", "heard": "VelaNova, what is the codeword?"}
2025-09-23 09:21:28,544 [INFO] wake_remainder {"text": ", what is the codeword?"}
2025-09-23 09:21:28,544 [INFO] user_text_prefill {"text": ", what is the codeword?"}
2025-09-23 09:21:28,548 [INFO] retrieve_pre_ctx {"snippet": ", what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codewo"}
2025-09-23 09:21:28,552 [INFO] retrieve_context {"k": 6, "hits": 6, "ids": [47, 51, 55, 59, 63, 65], "pre_ctx_chars": 163}
2025-09-23 09:21:28,556 [INFO] retrieve_guard {"matched": false}
2025-09-23 09:21:32,523 [INFO] llm_done {"dur_ms": 3967}
2025-09-23 09:21:32,535 [INFO] tts_start {}
2025-09-23 09:21:35,406 [INFO] tts_synth {"engine": "piper", "dur_ms": 2871}
2025-09-23 09:21:36,590 [INFO] await_wake {"mode": "text"}
2025-09-23 09:36:54,777 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log", "time": "2025-09-23T09:36:54"}
2025-09-23 09:36:54,777 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-23 09:36:54,777 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-23 09:36:56,368 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-23 09:36:56,376 [INFO] memory_doc {"doc_id": "05ee17af90fc4755b24e4db540cc0a6e"}
2025-09-23 09:36:56,376 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-23 09:36:56,376 [INFO] await_wake {"mode": "text"}
2025-09-23 09:37:04,722 [INFO] heard_text {"text": "VelaNova, store this fact: the codeword is mango-73."}
2025-09-23 09:37:04,722 [INFO] wake_detected {"via": "text", "heard": "VelaNova, store this fact: the codeword is mango-73."}
2025-09-23 09:37:04,723 [INFO] wake_remainder {"text": ", store this fact: the codeword is mango-73."}
2025-09-23 09:37:04,724 [INFO] user_text_prefill {"text": ", store this fact: the codeword is mango-73."}
2025-09-23 09:37:04,737 [INFO] store_codeword {"token": "mango-73"}
2025-09-23 09:37:04,738 [INFO] tts_start {}
2025-09-23 09:37:08,074 [INFO] tts_synth {"engine": "piper", "dur_ms": 3336}
2025-09-23 09:37:09,732 [INFO] await_wake {"mode": "text"}
2025-09-23 09:37:22,192 [INFO] heard_text {"text": "VelaNova, what is the codeword?"}
2025-09-23 09:37:22,192 [INFO] wake_detected {"via": "text", "heard": "VelaNova, what is the codeword?"}
2025-09-23 09:37:22,192 [INFO] wake_remainder {"text": ", what is the codeword?"}
2025-09-23 09:37:22,192 [INFO] user_text_prefill {"text": ", what is the codeword?"}
2025-09-23 09:37:22,194 [INFO] retrieve_pre_ctx {"snippet": ", what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codewo"}
2025-09-23 09:37:22,196 [INFO] retrieve_context {"k": 6, "hits": 6, "ids": [47, 51, 55, 59, 63, 65], "pre_ctx_chars": 163}
2025-09-23 09:37:22,198 [INFO] retrieve_guard {"matched": false, "pre_ctx_chars": 163, "hits": 6}
2025-09-23 09:37:26,088 [INFO] llm_done {"dur_ms": 3889}
2025-09-23 09:37:26,101 [INFO] tts_start {}
2025-09-23 09:37:28,984 [INFO] tts_synth {"engine": "piper", "dur_ms": 2882}
2025-09-23 09:37:29,833 [INFO] await_wake {"mode": "text"}
2025-09-23 09:59:40,909 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log", "time": "2025-09-23T09:59:40"}
2025-09-23 09:59:40,909 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-23 09:59:40,909 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-23 09:59:41,986 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-23 09:59:41,994 [INFO] memory_doc {"doc_id": "17237d32ab024415a562595057a35241"}
2025-09-23 09:59:41,994 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-23 09:59:41,994 [INFO] await_wake {"mode": "text"}
2025-09-23 11:55:07,039 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log", "time": "2025-09-23T11:55:07"}
2025-09-23 11:55:07,039 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-23 11:55:07,039 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-23 11:55:08,275 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-23 11:55:08,283 [INFO] memory_doc {"doc_id": "e5c35bbd0c09421c8a5b3aaa62b18233"}
2025-09-23 11:55:08,283 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-23 11:55:08,283 [INFO] await_wake {"mode": "text"}
2025-09-23 11:55:12,847 [INFO] heard_text {"text": "VelaNova, what is the codeword?"}
2025-09-23 11:55:12,847 [INFO] wake_detected {"via": "text", "heard": "VelaNova, what is the codeword?"}
2025-09-23 11:55:12,848 [INFO] wake_remainder {"text": ", what is the codeword?"}
2025-09-23 11:55:12,848 [INFO] user_text_prefill {"text": ", what is the codeword?"}
2025-09-23 11:55:12,850 [INFO] retrieve_pre_ctx {"snippet": ", what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codeword?\n---\n, what is the codewo"}
2025-09-23 11:55:12,852 [INFO] retrieve_context {"k": 6, "hits": 6, "ids": [47, 51, 55, 59, 63, 65], "pre_ctx_chars": 163}
2025-09-23 11:55:12,855 [INFO] retrieve_guard {"matched": true, "token": "mango-73", "source": "probe", "probe": "code word"}
2025-09-23 11:55:12,868 [INFO] tts_start {}
2025-09-23 11:55:15,851 [INFO] tts_synth {"engine": "piper", "dur_ms": 2983}
2025-09-23 11:55:17,590 [INFO] await_wake {"mode": "text"}
2025-09-23 11:55:17,590 [INFO] await_wake {"mode": "text"}
2025-09-23 12:27:59,985 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log", "time": "2025-09-23T12:27:59"}
2025-09-23 12:27:59,985 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-23 12:27:59,986 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-23 12:28:01,097 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-23 12:28:01,106 [INFO] memory_doc {"doc_id": "5f7307efa76748eead31351c74fb1a3d"}
2025-09-23 12:28:01,106 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-23 12:28:01,106 [INFO] await_wake {"mode": "text"}
2025-09-23 12:28:04,506 [INFO] heard_text {"text": "VelaNova, what\u2019s the codeword exactly?"}
2025-09-23 12:28:04,507 [INFO] wake_detected {"via": "text", "heard": "VelaNova, what\u2019s the codeword exactly?"}
2025-09-23 12:28:04,508 [INFO] wake_remainder {"text": ", what\u2019s the codeword exactly?"}
2025-09-23 12:28:04,508 [INFO] user_text_prefill {"text": ", what\u2019s the codeword exactly?"}
2025-09-23 12:28:04,511 [INFO] retrieve_pre_ctx {"snippet": "mango-73\n---\n, what is the codeword?\n---\n1\n---\n, what is the codeword?\n---\nThe codeword is \"mango-73\".\n---\n, store this fact: the codeword is mango-73."}
2025-09-23 12:28:04,512 [INFO] retrieve_context {"k": 6, "hits": 0, "ids": [], "pre_ctx_chars": 151}
2025-09-23 12:28:04,512 [INFO] retrieve_guard {"matched": true, "token": "mango-73", "source": "pre_ctx"}
2025-09-23 12:28:04,526 [INFO] tts_start {}
2025-09-23 12:28:07,611 [INFO] tts_synth {"engine": "piper", "dur_ms": 3084}
2025-09-23 12:28:09,100 [INFO] await_wake {"mode": "text"}
2025-09-23 12:28:09,100 [INFO] await_wake {"mode": "text"}
2025-09-23 12:33:40,090 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log", "time": "2025-09-23T12:33:40"}
2025-09-23 12:33:40,090 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-23 12:33:40,090 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-23 12:33:41,250 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-23 12:33:41,258 [INFO] memory_doc {"doc_id": "8974614866d64f6894df3c6f45c072ee"}
2025-09-23 12:33:41,258 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-23 12:33:41,258 [INFO] await_wake {"mode": "text"}
2025-09-23 12:33:45,567 [INFO] heard_text {"text": "VelaNova, store this fact: the project mascot is a dire wolf."}
2025-09-23 12:33:45,567 [INFO] wake_detected {"via": "text", "heard": "VelaNova, store this fact: the project mascot is a dire wolf."}
2025-09-23 12:33:45,568 [INFO] wake_remainder {"text": ", store this fact: the project mascot is a dire wolf."}
2025-09-23 12:33:45,568 [INFO] user_text_prefill {"text": ", store this fact: the project mascot is a dire wolf."}
2025-09-23 12:33:45,571 [INFO] retrieve_pre_ctx {"snippet": "mango-73\n---\n, what\u2019s the codeword exactly?\n---\nmango-73\n---\n, what is the codeword?\n---\n1\n---\n, what is the codeword?"}
2025-09-23 12:33:45,572 [INFO] retrieve_context {"k": 6, "hits": 0, "ids": [], "pre_ctx_chars": 118}
2025-09-23 12:33:46,002 [INFO] llm_done {"dur_ms": 429}
2025-09-23 12:33:46,016 [INFO] tts_start {}
2025-09-23 12:33:49,855 [INFO] tts_synth {"engine": "piper", "dur_ms": 3838}
2025-09-23 12:33:52,846 [INFO] await_wake {"mode": "text"}
2025-09-23 12:33:52,847 [INFO] await_wake {"mode": "text"}
2025-09-23 12:34:51,513 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log", "time": "2025-09-23T12:34:51"}
2025-09-23 12:34:51,513 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-23 12:34:51,513 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-23 12:34:52,673 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-23 12:34:52,681 [INFO] memory_doc {"doc_id": "9902fce2feb343458f324da443eaafb9"}
2025-09-23 12:34:52,681 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-23 12:34:52,681 [INFO] await_wake {"mode": "text"}
2025-09-23 12:34:56,184 [INFO] heard_text {"text": "VelaNova, what is the project mascot?"}
2025-09-23 12:34:56,184 [INFO] wake_detected {"via": "text", "heard": "VelaNova, what is the project mascot?"}
2025-09-23 12:34:56,185 [INFO] wake_remainder {"text": ", what is the project mascot?"}
2025-09-23 12:34:56,185 [INFO] user_text_prefill {"text": ", what is the project mascot?"}
2025-09-23 12:34:56,188 [INFO] retrieve_pre_ctx {"snippet": "The VelaNova project mascot is a dire wolf.\n---\n, store this fact: the project mascot is a dire wolf.\n---\nmango-73\n---\n, what\u2019s the codeword exactly?\n---\nmango-"}
2025-09-23 12:34:56,189 [INFO] retrieve_context {"k": 6, "hits": 0, "ids": [], "pre_ctx_chars": 190}
2025-09-23 12:34:56,583 [INFO] llm_done {"dur_ms": 393}
2025-09-23 12:34:56,595 [INFO] tts_start {}
2025-09-23 12:35:00,460 [INFO] tts_synth {"engine": "piper", "dur_ms": 3864}
2025-09-23 12:35:03,420 [INFO] await_wake {"mode": "text"}
2025-09-23 12:35:03,421 [INFO] await_wake {"mode": "text"}
2025-09-23 12:37:06,565 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250923.log", "time": "2025-09-23T12:37:06"}
2025-09-23 12:37:06,565 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-23 12:37:06,565 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-23 12:37:07,977 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-23 12:37:07,984 [INFO] memory_doc {"doc_id": "7da7bffc18e74d189d7d04182c9c8685"}
2025-09-23 12:37:07,985 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-23 12:37:07,985 [INFO] await_wake {"mode": "text"}
2025-09-23 12:37:09,785 [INFO] heard_text {"text": "VelaNova, using memory only, answer in one line: codeword=<token>; mascot=<value>."}
2025-09-23 12:37:09,785 [INFO] wake_detected {"via": "text", "heard": "VelaNova, using memory only, answer in one line: codeword=<token>; mascot=<value>."}
2025-09-23 12:37:09,786 [INFO] wake_remainder {"text": ", using memory only, answer in one line: codeword=<token>; mascot=<value>."}
2025-09-23 12:37:09,786 [INFO] user_text_prefill {"text": ", using memory only, answer in one line: codeword=<token>; mascot=<value>."}
2025-09-23 12:37:09,789 [INFO] retrieve_pre_ctx {"snippet": "The VelaNova project mascot is a dire wolf.\n---\n, what is the project mascot?\n---\nThe VelaNova project mascot is a dire wolf.\n---\n, store this fact: the project"}
2025-09-23 12:37:09,791 [INFO] retrieve_context {"k": 6, "hits": 0, "ids": [], "pre_ctx_chars": 231}
2025-09-23 12:37:09,797 [INFO] retrieve_guard {"matched": false, "pre_ctx_chars": 231, "hits": 0}
2025-09-23 12:37:10,231 [INFO] llm_done {"dur_ms": 433}
2025-09-23 12:37:10,245 [INFO] tts_start {}
2025-09-23 12:37:13,782 [INFO] tts_synth {"engine": "piper", "dur_ms": 3536}
2025-09-23 12:37:17,555 [INFO] await_wake {"mode": "text"}
2025-09-23 12:37:17,555 [INFO] await_wake {"mode": "text"}
```


## settings.yaml snapshot (keys only, redacted)

```
# V2 — Phase C/D: live mic + hard/soft wake, Whisper (CUDA), Piper (local), and durable local memory (SQLite)
# Notes:
# - Hard-wake uses *.onnx models in /home/pudding/Projects/VelaNova/models/wake/
# - "hey jarvis"/"hey mycroft"/"alexa" are hard-wake (KWS); "velanova" variants are soft-wake (STT fallback).
# - Mic uses system default (index -1) so Pulse/PipeWire handle 48k↔16k reliably.
# - Phase D uses a local SQLite DB under ~/Projects/VelaNova/memory/db/memory.sqlite.

version: 2

wake:
  engine: soft
  mode: text
  model_dir: /home/pudding/Projects/VelaNova/models/wake
  model_glob: "*.onnx"
  sensitivity: 0.48
  min_silence_ms: 600
  trigger_debounce_ms: 1500
  phrases:
    # Hard-wake (requires matching .onnx models)
    - hey jarvis
    - hey mycroft
    - alexa
    # Soft-wake (phrase-checked by STT)
    - velanova
    - hey velanova
  stop_phrase: "sleep nova"

stt:
  engine: soft
  mode: text
  impl: faster-whisper
  model: small
  device: cuda                # cuda | cpu
  compute_type: int8_float16
  beam_size: 1
  sample_rate: 16000
  vad:
    enable: true
    method: webrtc
    max_silence_ms: 900
  chunk_ms: 2048

tts:
  engine: soft
  mode: text
  voice: en_GB-cori-high
  voice_path: /home/pudding/Projects/VelaNova/models/piper/en/en_GB/cori/high/en_GB-cori-high.onnx
  config_path: /home/pudding/Projects/VelaNova/models/piper/en/en_GB/cori/high/en_GB-cori-high.onnx.json
  sample_rate: 22050
  rate: 1.00
  volume: 1.00
  length_scale: 1.00
  noise_scale: 0.667
  temp_wav: /home/pudding/Projects/VelaNova/logs/last_output.wav

llm:
  provider: ollama
  endpoint: http://localhost:11434
  model: llama3.2:3b
  options:
    num_ctx: 4096
    temperature: 0.5
    max_tokens: 256
  system_prompt: |
    You are VelaNova. Be concise and clear when speaking responses aloud.

# === Phase D: Durable Memory (local only) ===
memory:
  engine: sqlite
  path: /home/pudding/Projects/VelaNova/memory/db/memory.sqlite
  recall:
    k: 5
  retention:
    max_turns: 5000
    prune_on_start: false
  logging:
    enabled: true

orchestrator:
  input_device_index: -1
  output_device_index: -1
  max_turn_seconds: 45
  listen_timeout_seconds: 12
  grace_after_tts_ms: 300
  mode: text

logging:
  file: /home/pudding/Projects/VelaNova/logs/voice_loop-%Y%m%d.log
  level: INFO
  rotate_days: 7

# Guardrails
connected:
  enabled: false

security:
  egress_block_expected: true
```


## Summary checklist

- [ ] All containers healthy (docker compose ps)
- [ ] Wake word active (no false triggers in quiet room)
- [ ] STT on GPU (faster-whisper) confirmed in logs
- [ ] TTS voice OK (Piper running, voice selected)
- [ ] LLM models present in Ollama (deepseek-r1:7b, qwen2.5-coder:7b)
- [ ] Orchestrator round-trip < 2.5s median
- [ ] Memory DB directory present (.chroma)

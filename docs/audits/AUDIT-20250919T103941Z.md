# VelaNova Audit — 20250919T103941Z (UTC)

- Base: /home/pudding/Projects/VelaNova
- Host: Linux pop-os 6.16.3-76061603-generic #202508231538~1757385336~22.04~8f363f2 SMP PREEMPT_DYNAMIC Tue S x86_64 x86_64 x86_64 GNU/Linux
- User: pudding


## OS / Kernel / GPU / Tooling

```
OS:
No LSB modules are available.
Distributor ID:	Pop
Description:	Pop!_OS 22.04 LTS
Release:	22.04
Codename:	jammy

Kernel:
Linux 6.16.3-76061603-generic

GPU:
GPU 0: NVIDIA GeForce RTX 2070 with Max-Q Design (UUID: GPU-e03951aa-f813-5ebe-a5a0-bc071e39b32e)
name, driver_version, memory.total [MiB]
NVIDIA GeForce RTX 2070 with Max-Q Design, 570.172.08, 8192 MiB

Python:
Python 3.10.12

Docker:
Docker version 27.5.1, build 27.5.1-0ubuntu3~22.04.2
Docker Compose version v2.39.2

NVIDIA Container Toolkit:
cli-version: 1.12.1
lib-version: 1.12.1
build date: 2023-03-21T16:54+00:00
build revision: 41335937dcf88680b29dca7d23b4102c2d2f2f2f
build compiler: x86_64-linux-gnu-gcc-9 11.2.0
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -fPIC -Wdate-time -D_FORTIFY_SOURCE=2 -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fplan9-extensions -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -fPIC -g -O2 -fdebug-prefix-map=/home/jenkins/workspace/pop-os/repos/_build/ci/git/libnvidia-container/d17aa6f4960e1d386abadf2288403efa4c1753ab/jammy/partial.source/archive=. -fstack-protector-strong -Wformat -Werror=format-security -I/usr/include/tirpc -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections -Wl,-Bsymbolic-functions -Wl,-z,relro
```


## Project tree (depth 3)

```
/home/pudding/Projects/VelaNova
├── compose
│   ├── data
│   │   └── open-webui
│   ├── docker-compose.yml
│   └── docker-compose.yml.bak
├── config
│   ├── settings.yaml
│   └── voice.yaml
├── docs
│   ├── audits
│   │   ├── AUDIT-20250917T173921Z.md
│   │   ├── AUDIT-20250917T174322Z.md
│   │   ├── AUDIT-20250917T175130Z.md
│   │   ├── AUDIT-20250917T191059Z.md
│   │   ├── AUDIT-20250918T103939Z.md
│   │   ├── AUDIT-20250918T104303Z.md
│   │   └── AUDIT-20250919T103941Z.md
│   ├── IMPLEMENTATION_PLAN.md
│   ├── INSTRUCTIONS.md
│   ├── OPERATIONS.md
│   ├── PHASE_A_ACCEPTANCE.md
│   ├── PHASE_A_ACCEPTANCE.md.20250917T191059Z.bak
│   ├── PHASE_B_ACCEPTANCE.md
│   ├── PHASE_C_ACCEPTANCE.md
│   ├── PHASE_C_COMPLETION.md
│   ├── PHASE_C_PROOF_20250919.txt
│   ├── PHASE_D_ACCEPTANCE.md
│   ├── Phase E Completion (Dev Mode).md
│   └── SNAPSHOTS.md
├── logs
│   ├── last_output.wav
│   ├── mic_probe.wav
│   ├── tts_smoke.wav
│   ├── voice_loop-20250915.log
│   ├── voice_loop-20250916.log
│   ├── voice_loop-20250917.log
│   ├── voice_loop-20250918.log
│   ├── voice_loop-20250919.log
│   ├── voice_loop-20250919.log.1
│   ├── voice_loop-20250919.log.2
│   ├── voice_loop-20250919.log.3
│   ├── voice_loop-20250919.log.4
│   ├── voice_loop-20250919.log.5
│   ├── voice_loop-20250919.log.6
│   └── voice_loop-20250919.log.7
├── memory
│   ├── db
│   │   └── memory.sqlite
│   ├── docs
│   ├── index
│   ├── logs
│   └── tmp
├── models
│   ├── ollama
│   │   ├── id_ed25519
│   │   ├── id_ed25519.pub
│   │   └── models
│   ├── oww
│   ├── piper
│   │   └── en
│   ├── wake
│   │   ├── alexa_v0.1.tflite
│   │   ├── embedding_model.tflite
│   │   ├── hey_jarvis_v0.1.tflite
│   │   ├── hey_mycroft_v0.1.tflite
│   │   ├── hey_rhasspy_v0.1.tflite
│   │   ├── melspectrogram.tflite
│   │   ├── timer_v0.1.tflite
│   │   └── weather_v0.1.tflite
│   └── whisper
│       └── small
├── orchestrator
│   ├── check_env.py
│   ├── memory_selftest.py
│   ├── memory_store.py
│   ├── mic_probe.py
│   ├── __pycache__
│   │   ├── memory_store.cpython-310.pyc
│   │   └── voice_loop.cpython-310.pyc
│   └── voice_loop.py
└── tools
    └── audit.sh

25 directories, 57 files
```


## Key files present

```
[OK] orchestrator/voice_loop.py (29386 bytes)
[OK] config/settings.yaml (2658 bytes)
[OK] compose/docker-compose.yml (727 bytes)
[OK] docs/SNAPSHOTS.md (1333 bytes)
```


## Python virtualenv packages (.venv)

```
Python 3.10.12
ctranslate2        4.6.0
faster-whisper     1.2.0
onnxruntime        1.16.3
openwakeword       0.6.0
piper-tts          1.3.0
scipy              1.15.3
sounddevice        0.5.2
soundfile          0.13.1
```


## Listening ports (Jarvis-related)

```
LISTEN 0      4096         0.0.0.0:11434      0.0.0.0:*                                          
LISTEN 0      4096         0.0.0.0:3000       0.0.0.0:*                                          
LISTEN 0      4096            [::]:11434         [::]:*                                          
LISTEN 0      4096            [::]:3000          [::]:*                                          
```


## Docker Compose status

```
NAME          IMAGE                                  COMMAND               SERVICE      CREATED      STATUS                PORTS
vela_ollama   ollama/ollama:0.3.13                   "/bin/ollama serve"   ollama       2 days ago   Up 2 days             0.0.0.0:11434->11434/tcp, [::]:11434->11434/tcp
vela_webui    ghcr.io/open-webui/open-webui:latest   "bash start.sh"       open-webui   2 days ago   Up 2 days (healthy)   0.0.0.0:3000->8080/tcp, [::]:3000->8080/tcp
```


## Ollama models available

```
```


## Audio devices (ALSA/Pulse)

```
**** List of CAPTURE Hardware Devices ****
card 0: PCH [HDA Intel PCH], device 0: ALC295 Analog [ALC295 Analog]
  Subdevices: 1/1
  Subdevice #0: subdevice #0

49	alsa_output.pci-0000_00_1f.3.analog-stereo.monitor	PipeWire	s32le 2ch 48000Hz	RUNNING
50	alsa_input.pci-0000_00_1f.3.analog-stereo	PipeWire	s32le 2ch 48000Hz	SUSPENDED
```


## Latest orchestrator logs

```
Showing: /home/pudding/Projects/VelaNova/logs/voice_loop-20250919.log
2025-09-19 11:50:27,310 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-19 11:50:27,318 [INFO] memory_doc {"doc_id": "9d4023f74acf45c69719fd2491fddbea"}
2025-09-19 11:50:27,319 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-19 11:50:27,319 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:50:27,319 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:50:29,745 [INFO] capture_end {"sec": 2.31, "blocks": 77}
2025-09-19 11:50:29,746 [INFO] await_wake_capture {"len_ms": 2310}
2025-09-19 11:50:31,035 [INFO] stt_done {"dur_ms": 1288, "len_s": 2.31}
2025-09-19 11:50:31,035 [INFO] heard_text {"text": "Wake Balano."}
2025-09-19 11:50:31,036 [INFO] wake_fuzzy_hit {"heard": "Wake Balano.", "match": "kebalano", "target": "velanova"}
2025-09-19 11:50:31,037 [INFO] wake_detected {"via": "mic", "heard": "Wake Balano."}
2025-09-19 11:50:31,037 [INFO] wake_remainder {"text": "Wake Balano."}
2025-09-19 11:50:31,037 [INFO] user_text_prefill {"text": "Wake Balano."}
2025-09-19 11:50:31,857 [INFO] llm_done {"dur_ms": 817}
2025-09-19 11:50:31,871 [INFO] tts_start {}
2025-09-19 11:50:36,867 [INFO] tts_synth {"engine": "piper", "dur_ms": 4995}
2025-09-19 11:50:45,765 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:50:45,765 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:50:48,181 [INFO] capture_end {"sec": 2.34, "blocks": 78}
2025-09-19 11:50:48,181 [INFO] await_wake_capture {"len_ms": 2340}
2025-09-19 11:50:48,688 [INFO] stt_retry_vad {"used": true}
2025-09-19 11:50:48,689 [INFO] stt_done {"dur_ms": 506, "len_s": 2.34}
2025-09-19 11:50:48,689 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:50:48,689 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:50:51,104 [INFO] capture_end {"sec": 1.47, "blocks": 49}
2025-09-19 11:50:51,105 [INFO] await_wake_capture {"len_ms": 1470}
2025-09-19 11:50:51,540 [INFO] stt_done {"dur_ms": 434, "len_s": 1.47}
2025-09-19 11:50:51,540 [INFO] heard_text {"text": "you are well enough."}
2025-09-19 11:50:51,541 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:50:51,542 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:50:53,962 [INFO] capture_end {"sec": 0.48, "blocks": 16}
2025-09-19 11:50:53,963 [INFO] await_wake_capture {"len_ms": 480}
2025-09-19 11:50:54,384 [INFO] stt_retry_vad {"used": true}
2025-09-19 11:50:54,384 [INFO] stt_done {"dur_ms": 420, "len_s": 0.48}
2025-09-19 11:50:54,385 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:50:54,385 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:50:56,800 [INFO] capture_end {"sec": 1.89, "blocks": 63}
2025-09-19 11:50:56,800 [INFO] await_wake_capture {"len_ms": 1890}
2025-09-19 11:50:57,243 [INFO] stt_retry_vad {"used": true}
2025-09-19 11:50:57,243 [INFO] stt_done {"dur_ms": 442, "len_s": 1.89}
2025-09-19 11:50:57,243 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:50:57,244 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:50:59,658 [INFO] capture_end {"sec": 1.98, "blocks": 66}
2025-09-19 11:50:59,659 [INFO] await_wake_capture {"len_ms": 1980}
2025-09-19 11:51:00,100 [INFO] stt_retry_vad {"used": true}
2025-09-19 11:51:00,100 [INFO] stt_done {"dur_ms": 440, "len_s": 1.98}
2025-09-19 11:51:00,101 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:51:00,101 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:51:02,517 [INFO] capture_end {"sec": 1.26, "blocks": 42}
2025-09-19 11:51:02,517 [INFO] await_wake_capture {"len_ms": 1260}
2025-09-19 11:51:02,952 [INFO] stt_retry_vad {"used": true}
2025-09-19 11:51:02,952 [INFO] stt_done {"dur_ms": 434, "len_s": 1.26}
2025-09-19 11:51:02,952 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:51:02,953 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:51:15,973 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250919.log", "time": "2025-09-19T11:51:15"}
2025-09-19 11:51:15,973 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-19 11:51:15,973 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-19 11:51:17,332 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-19 11:51:17,340 [INFO] memory_doc {"doc_id": "e9cd07e27ad642a696ef64592b89edca"}
2025-09-19 11:51:17,340 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-19 11:51:17,340 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:51:17,340 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:51:19,745 [INFO] capture_end {"sec": 2.31, "blocks": 77}
2025-09-19 11:51:19,745 [INFO] await_wake_capture {"len_ms": 2310}
2025-09-19 11:51:20,478 [INFO] stt_done {"dur_ms": 732, "len_s": 2.31}
2025-09-19 11:51:20,478 [INFO] heard_text {"text": "Wake nova"}
2025-09-19 11:51:20,480 [INFO] wake_fuzzy_hit {"heard": "Wake nova", "match": "wakenova", "target": "velanova"}
2025-09-19 11:51:20,480 [INFO] wake_detected {"via": "mic", "heard": "Wake nova"}
2025-09-19 11:51:20,481 [INFO] wake_remainder {"text": "Wake nova"}
2025-09-19 11:51:20,481 [INFO] user_text_prefill {"text": "Wake nova"}
2025-09-19 11:51:21,319 [INFO] llm_done {"dur_ms": 835}
2025-09-19 11:51:21,334 [INFO] tts_start {}
2025-09-19 11:51:26,329 [INFO] tts_synth {"engine": "piper", "dur_ms": 4994}
2025-09-19 11:51:35,134 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:51:35,134 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:51:37,559 [INFO] capture_end {"sec": 2.37, "blocks": 79}
2025-09-19 11:51:37,560 [INFO] await_wake_capture {"len_ms": 2370}
2025-09-19 11:51:48,561 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250919.log", "time": "2025-09-19T11:51:48"}
2025-09-19 11:51:48,561 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-19 11:51:48,561 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-19 11:51:50,880 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-19 11:51:50,889 [INFO] memory_doc {"doc_id": "899a8401a0f34add90462b9dbed3cc09"}
2025-09-19 11:51:50,889 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-19 11:51:50,889 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:51:50,890 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:51:53,318 [INFO] capture_end {"sec": 2.31, "blocks": 77}
2025-09-19 11:51:53,318 [INFO] await_wake_capture {"len_ms": 2310}
2025-09-19 11:51:53,919 [INFO] stt_done {"dur_ms": 599, "len_s": 2.31}
2025-09-19 11:51:53,919 [INFO] heard_text {"text": "Fela, Nova, what?"}
2025-09-19 11:51:53,920 [INFO] wake_fuzzy_hit {"heard": "Fela, Nova, what?", "match": "felanova", "target": "velanova"}
2025-09-19 11:51:53,921 [INFO] wake_detected {"via": "mic", "heard": "Fela, Nova, what?"}
2025-09-19 11:51:53,921 [INFO] wake_remainder {"text": "Fela, Nova, what?"}
2025-09-19 11:51:53,922 [INFO] user_text_prefill {"text": "Fela, Nova, what?"}
2025-09-19 11:51:54,828 [INFO] llm_done {"dur_ms": 904}
2025-09-19 11:51:54,843 [INFO] tts_start {}
2025-09-19 11:51:59,941 [INFO] tts_synth {"engine": "piper", "dur_ms": 5097}
2025-09-19 11:52:09,281 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:52:09,281 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:52:17,318 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250919.log", "time": "2025-09-19T11:52:17"}
2025-09-19 11:52:17,318 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-19 11:52:17,318 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-19 11:52:19,789 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-19 11:52:19,797 [INFO] memory_doc {"doc_id": "f5b257cf75fb4a21802d92df8ce48abf"}
2025-09-19 11:52:19,797 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-19 11:52:19,797 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:52:19,797 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:52:28,076 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250919.log", "time": "2025-09-19T11:52:28"}
2025-09-19 11:52:28,076 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-19 11:52:28,076 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-19 11:52:30,604 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-19 11:52:30,612 [INFO] memory_doc {"doc_id": "7e03edbbf47c45efb470db506969b537"}
2025-09-19 11:52:30,612 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-19 11:52:30,612 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:52:30,612 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:52:33,040 [INFO] capture_end {"sec": 2.31, "blocks": 77}
2025-09-19 11:52:33,040 [INFO] await_wake_capture {"len_ms": 2310}
2025-09-19 11:52:33,639 [INFO] stt_done {"dur_ms": 597, "len_s": 2.31}
2025-09-19 11:52:33,639 [INFO] heard_text {"text": "What time is?"}
2025-09-19 11:52:33,641 [INFO] wake_question_heuristic {"heard": "What time is?"}
2025-09-19 11:52:33,641 [INFO] wake_remainder {"text": "What time is?"}
2025-09-19 11:52:33,642 [INFO] user_text_prefill {"text": "What time is?"}
2025-09-19 11:52:33,657 [INFO] tts_start {}
2025-09-19 11:52:36,740 [INFO] tts_synth {"engine": "piper", "dur_ms": 3083}
2025-09-19 11:52:38,537 [INFO] await_wake {"mode": "mic"}
2025-09-19 11:52:38,538 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 11:52:40,958 [INFO] capture_end {"sec": 2.31, "blocks": 77}
2025-09-19 11:52:40,958 [INFO] await_wake_capture {"len_ms": 2310}
2025-09-19 12:14:54,893 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250919.log", "time": "2025-09-19T12:14:54"}
2025-09-19 12:14:54,893 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-19 12:14:54,893 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-19 12:14:55,966 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-19 12:14:55,973 [INFO] memory_doc {"doc_id": "0fef431eeb1d4270a49696db7f9b1fe1"}
2025-09-19 12:14:55,973 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-19 12:14:55,974 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:14:55,974 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:14:58,380 [INFO] capture_end {"sec": 2.31, "blocks": 77}
2025-09-19 12:14:58,380 [INFO] await_wake_capture {"len_ms": 2310}
2025-09-19 12:14:59,124 [INFO] stt_done {"dur_ms": 743, "len_s": 2.31}
2025-09-19 12:14:59,125 [INFO] heard_text {"text": "Wake Never"}
2025-09-19 12:14:59,126 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:14:59,127 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:15:01,535 [INFO] capture_end {"sec": 1.8, "blocks": 60}
2025-09-19 12:15:01,536 [INFO] await_wake_capture {"len_ms": 1800}
2025-09-19 12:15:02,048 [INFO] stt_done {"dur_ms": 511, "len_s": 1.8}
2025-09-19 12:15:02,048 [INFO] heard_text {"text": "What time is it?"}
2025-09-19 12:15:02,048 [INFO] wake_question_heuristic {"heard": "What time is it?"}
2025-09-19 12:15:02,049 [INFO] wake_remainder {"text": "What time is it?"}
2025-09-19 12:15:02,049 [INFO] user_text_prefill {"text": "What time is it?"}
2025-09-19 12:15:02,061 [INFO] tts_start {}
2025-09-19 12:15:05,095 [INFO] tts_synth {"engine": "piper", "dur_ms": 3033}
2025-09-19 12:15:06,785 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:15:06,786 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:15:09,218 [INFO] capture_end {"sec": 2.37, "blocks": 79}
2025-09-19 12:15:09,219 [INFO] await_wake_capture {"len_ms": 2370}
2025-09-19 12:15:09,812 [INFO] stt_retry_vad {"used": true}
2025-09-19 12:15:09,813 [INFO] stt_done {"dur_ms": 593, "len_s": 2.37}
2025-09-19 12:15:09,813 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:15:09,813 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:15:12,226 [INFO] capture_end {"sec": 1.71, "blocks": 57}
2025-09-19 12:15:12,226 [INFO] await_wake_capture {"len_ms": 1710}
2025-09-19 12:15:12,743 [INFO] stt_retry_vad {"used": true}
2025-09-19 12:15:12,744 [INFO] stt_done {"dur_ms": 517, "len_s": 1.71}
2025-09-19 12:15:12,744 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:15:12,745 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:15:15,148 [INFO] capture_end {"sec": 2.34, "blocks": 78}
2025-09-19 12:15:15,149 [INFO] await_wake_capture {"len_ms": 2340}
2025-09-19 12:15:16,210 [INFO] stt_retry_vad {"used": true}
2025-09-19 12:15:16,210 [INFO] stt_done {"dur_ms": 1061, "len_s": 2.34}
2025-09-19 12:15:16,210 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:15:16,210 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:15:18,626 [INFO] capture_end {"sec": 2.34, "blocks": 78}
2025-09-19 12:15:18,627 [INFO] await_wake_capture {"len_ms": 2340}
2025-09-19 12:15:19,141 [INFO] stt_retry_vad {"used": true}
2025-09-19 12:15:19,141 [INFO] stt_done {"dur_ms": 513, "len_s": 2.34}
2025-09-19 12:15:19,141 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:15:19,141 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:15:21,548 [INFO] capture_end {"sec": 2.04, "blocks": 68}
2025-09-19 12:15:21,549 [INFO] await_wake_capture {"len_ms": 2040}
2025-09-19 12:15:22,199 [INFO] stt_done {"dur_ms": 650, "len_s": 2.04}
2025-09-19 12:15:22,199 [INFO] heard_text {"text": "Wake never."}
2025-09-19 12:15:22,200 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:15:22,200 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:15:24,621 [INFO] capture_end {"sec": 2.22, "blocks": 74}
2025-09-19 12:15:24,621 [INFO] await_wake_capture {"len_ms": 2220}
2025-09-19 12:15:25,175 [INFO] stt_retry_vad {"used": true}
2025-09-19 12:15:25,176 [INFO] stt_done {"dur_ms": 553, "len_s": 2.22}
2025-09-19 12:15:25,176 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:15:25,176 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
2025-09-19 12:15:27,585 [INFO] capture_end {"sec": 2.34, "blocks": 78}
2025-09-19 12:15:27,585 [INFO] await_wake_capture {"len_ms": 2340}
2025-09-19 12:15:28,142 [INFO] stt_done {"dur_ms": 556, "len_s": 2.34}
2025-09-19 12:15:28,142 [INFO] heard_text {"text": "Why is it?"}
2025-09-19 12:15:28,142 [INFO] wake_question_heuristic {"heard": "Why is it?"}
2025-09-19 12:15:28,143 [INFO] wake_remainder {"text": "Why is it?"}
2025-09-19 12:15:28,143 [INFO] user_text_prefill {"text": "Why is it?"}
2025-09-19 12:15:29,076 [INFO] llm_done {"dur_ms": 931}
2025-09-19 12:15:29,086 [INFO] tts_start {}
2025-09-19 12:15:36,145 [INFO] tts_synth {"engine": "piper", "dur_ms": 7058}
2025-09-19 12:15:46,351 [INFO] await_wake {"mode": "mic"}
2025-09-19 12:15:46,351 [INFO] capture_begin {"timeout_s": 2.4, "vad": "rms"}
```


## settings.yaml snapshot (keys only, redacted)

```
# V2 — Phase C live mic + hard wake-word (OpenWakeWord ONNX-CPU) + Whisper (CUDA, low-VRAM) + Piper (local)
# Notes:
# - Hard-wake uses the *.onnx models in /home/pudding/Projects/VelaNova/models/wake/
# - "hey jarvis" / "hey mycroft" / "alexa" are hard-wake (KWS); "velanova" variants are soft-wake (STT fallback if supported).
# - Mic uses system default (index -1) so Pulse/PipeWire can handle 48k↔16k resampling reliably.

version: 2

wake:
  engine: soft
  mode: text
  model_dir: /home/pudding/Projects/VelaNova/models/wake
  model_glob: "*.onnx"
  sensitivity: 0.48             # raise if misses; lower if false wakes (0.35–0.60 sane)
  min_silence_ms: 600
  trigger_debounce_ms: 1500
  phrases:
    # Hard-wake (must have matching .onnx model files)
    - hey jarvis
    - hey mycroft
    - alexa
    # Soft-wake fallbacks (via STT phrase check, if supported by your loop)
    - velanova
    - hey velanova
  stop_phrase: "sleep nova"

stt:
  engine: soft
  mode: text
  impl: faster-whisper
  model: small                  # your local CT2 "small" model
  device: cuda                  # cuda | cpu
  compute_type: int8_float16    # OOM-safe on 8GB VRAM, solid accuracy for short prompts
  beam_size: 1                  # latency + VRAM friendly
  sample_rate: 16000
  vad:
    enable: true
    method: webrtc              # simple; switch to "silero" later if desired
    max_silence_ms: 900
  chunk_ms: 2048                # streaming chunk size

tts:
  engine: soft
  mode: text
  voice: en_GB-cori-high
  voice_path: /home/pudding/Projects/VelaNova/models/piper/en/en_GB/cori/high/en_GB-cori-high.onnx
  config_path: /home/pudding/Projects/VelaNova/models/piper/en/en_GB/cori/high/en_GB-cori-high.onnx.json
  sample_rate: 22050
  rate: 1.00
  volume: 1.00
  length_scale: 1.00
  noise_scale: 0.667
  temp_wav: /home/pudding/Projects/VelaNova/logs/last_output.wav

llm:
  provider: ollama
  endpoint: http://localhost:11434
  model: llama3.2:3b
  options:
    num_ctx: 4096
    temperature: 0.5
    max_tokens: 256
  system_prompt: |
    You are VelaNova. Be concise and clear when speaking responses aloud.

orchestrator:
  input_device_index: -1        # system default (stable), Pulse/PipeWire resamples cleanly
  output_device_index: -1       # system default speakers
  max_turn_seconds: 45
  listen_timeout_seconds: 12
  grace_after_tts_ms: 300
  mode: mic                     # live mic loop

logging:
  file: /home/pudding/Projects/VelaNova/logs/voice_loop-%Y%m%d.log
  level: INFO
  rotate_days: 7

security:
  egress_block_expected: true

# Phase B — offline stance
connected.enabled: false
security.egress_block_expected: true
```


## Summary checklist

- [ ] All containers healthy (docker compose ps)
- [ ] Wake word active (no false triggers in quiet room)
- [ ] STT on GPU (faster-whisper) confirmed in logs
- [ ] TTS voice OK (Piper running, voice selected)
- [ ] LLM models present in Ollama (deepseek-r1:7b, qwen2.5-coder:7b)
- [ ] Orchestrator round-trip < 2.5s median
- [ ] Memory DB directory present (.chroma)

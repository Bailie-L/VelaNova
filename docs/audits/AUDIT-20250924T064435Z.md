# VelaNova Audit — 20250924T064435Z (UTC)

- Base: /home/pudding/Projects/VelaNova
- Host: Linux pop-os 6.16.3-76061603-generic #202508231538~1757385336~22.04~8f363f2 SMP PREEMPT_DYNAMIC Tue S x86_64 x86_64 x86_64 GNU/Linux
- User: pudding


## OS / Kernel / GPU / Tooling

```
OS:
No LSB modules are available.
Distributor ID:	Pop
Description:	Pop!_OS 22.04 LTS
Release:	22.04
Codename:	jammy

Kernel:
Linux 6.16.3-76061603-generic

GPU:
GPU 0: NVIDIA GeForce RTX 2070 with Max-Q Design (UUID: GPU-e03951aa-f813-5ebe-a5a0-bc071e39b32e)
name, driver_version, memory.total [MiB]
NVIDIA GeForce RTX 2070 with Max-Q Design, 570.172.08, 8192 MiB

Python:
Python 3.10.12

Docker:
Docker version 27.5.1, build 27.5.1-0ubuntu3~22.04.2
Docker Compose version v2.39.2

NVIDIA Container Toolkit:
cli-version: 1.12.1
lib-version: 1.12.1
build date: 2023-03-21T16:54+00:00
build revision: 41335937dcf88680b29dca7d23b4102c2d2f2f2f
build compiler: x86_64-linux-gnu-gcc-9 11.2.0
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -fPIC -Wdate-time -D_FORTIFY_SOURCE=2 -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fplan9-extensions -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -fPIC -g -O2 -fdebug-prefix-map=/home/jenkins/workspace/pop-os/repos/_build/ci/git/libnvidia-container/d17aa6f4960e1d386abadf2288403efa4c1753ab/jammy/partial.source/archive=. -fstack-protector-strong -Wformat -Werror=format-security -I/usr/include/tirpc -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections -Wl,-Bsymbolic-functions -Wl,-z,relro
```


## Project tree (depth 3)

```
/home/pudding/Projects/VelaNova
├── compose
│   ├── data
│   │   └── open-webui
│   ├── docker-compose.yml
│   └── docker-compose.yml.bak
├── config
│   ├── settings.yaml
│   └── voice.yaml
├── docs
│   ├── audits
│   │   ├── AUDIT-20250917T173921Z.md
│   │   ├── AUDIT-20250917T174322Z.md
│   │   ├── AUDIT-20250917T175130Z.md
│   │   ├── AUDIT-20250917T191059Z.md
│   │   ├── AUDIT-20250918T103939Z.md
│   │   ├── AUDIT-20250918T104303Z.md
│   │   ├── AUDIT-20250919T103941Z.md
│   │   ├── AUDIT-20250921T094932Z.md
│   │   ├── AUDIT-20250923T135405Z.md
│   │   └── AUDIT-20250924T064435Z.md
│   ├── IMPLEMENTATION_PLAN.md
│   ├── INSTRUCTIONS.md
│   ├── OPERATIONS.md
│   ├── PHASE_A_ACCEPTANCE.md
│   ├── PHASE_A_ACCEPTANCE.md.20250917T191059Z.bak
│   ├── PHASE_B_ACCEPTANCE.md
│   ├── PHASE_C_ACCEPTANCE.md
│   ├── PHASE_C_COMPLETION.md
│   ├── PHASE_C_PROOF_20250919.txt
│   ├── PHASE_D_ACCEPTANCE.md
│   ├── PHASE_E_ACCEPTANCE.md
│   ├── Phase E Completion (Dev Mode).md
│   └── SNAPSHOTS.md
├── logs
│   ├── last_output.wav
│   ├── mic_probe.wav
│   ├── tts_smoke.wav
│   ├── voice_loop-20250915.log
│   ├── voice_loop-20250916.log
│   ├── voice_loop-20250917.log
│   ├── voice_loop-20250918.log
│   ├── voice_loop-20250919.log
│   ├── voice_loop-20250919.log.1
│   ├── voice_loop-20250919.log.2
│   ├── voice_loop-20250919.log.3
│   ├── voice_loop-20250919.log.4
│   ├── voice_loop-20250919.log.5
│   ├── voice_loop-20250919.log.6
│   ├── voice_loop-20250919.log.7
│   ├── voice_loop-20250921.log
│   ├── voice_loop-20250923.log
│   └── voice_loop-20250924.log
├── memory
│   ├── db
│   │   └── memory.sqlite
│   ├── docs
│   ├── index
│   ├── logs
│   └── tmp
├── models
│   ├── llama3.2-coder.Modelfile
│   ├── ollama
│   │   ├── id_ed25519
│   │   ├── id_ed25519.pub
│   │   └── models
│   ├── oww
│   ├── piper
│   │   └── en
│   ├── wake
│   │   ├── alexa_v0.1.tflite
│   │   ├── embedding_model.tflite
│   │   ├── hey_jarvis_v0.1.tflite
│   │   ├── hey_mycroft_v0.1.tflite
│   │   ├── hey_rhasspy_v0.1.tflite
│   │   ├── melspectrogram.tflite
│   │   ├── timer_v0.1.tflite
│   │   └── weather_v0.1.tflite
│   └── whisper
│       └── small
├── orchestrator
│   ├── check_env.py
│   ├── memory_selftest.py
│   ├── memory_store.py
│   ├── mic_probe.py
│   ├── __pycache__
│   │   ├── memory_store.cpython-310.pyc
│   │   └── voice_loop.cpython-310.pyc
│   └── voice_loop.py
└── tools
    └── audit.sh

25 directories, 65 files
```


## Key files present

```
[OK] orchestrator/voice_loop.py (34202 bytes)
[OK] config/settings.yaml (2465 bytes)
[OK] compose/docker-compose.yml (727 bytes)
[OK] docs/SNAPSHOTS.md (1800 bytes)
```


## Python virtualenv packages (.venv)

```
Python 3.10.12
ctranslate2        4.6.0
faster-whisper     1.2.0
onnxruntime        1.16.3
openwakeword       0.6.0
piper-tts          1.3.0
scipy              1.15.3
sounddevice        0.5.2
soundfile          0.13.1
```


## Listening ports (Jarvis-related)

```
LISTEN 0      4096         0.0.0.0:11434      0.0.0.0:*                                         
LISTEN 0      4096         0.0.0.0:3000       0.0.0.0:*                                         
LISTEN 0      4096            [::]:11434         [::]:*                                         
LISTEN 0      4096            [::]:3000          [::]:*                                         
```


## Docker Compose status

```
NAME          IMAGE                                  COMMAND               SERVICE      CREATED      STATUS                PORTS
vela_ollama   ollama/ollama:0.3.13                   "/bin/ollama serve"   ollama       7 days ago   Up 7 days             0.0.0.0:11434->11434/tcp, [::]:11434->11434/tcp
vela_webui    ghcr.io/open-webui/open-webui:latest   "bash start.sh"       open-webui   7 days ago   Up 7 days (healthy)   0.0.0.0:3000->8080/tcp, [::]:3000->8080/tcp
```


## Ollama models available

```
```


## Audio devices (ALSA/Pulse)

```
**** List of CAPTURE Hardware Devices ****
card 0: PCH [HDA Intel PCH], device 0: ALC295 Analog [ALC295 Analog]
  Subdevices: 1/1
  Subdevice #0: subdevice #0

49	alsa_output.pci-0000_00_1f.3.analog-stereo.monitor	PipeWire	s32le 2ch 48000Hz	RUNNING
50	alsa_input.pci-0000_00_1f.3.analog-stereo	PipeWire	s32le 2ch 48000Hz	SUSPENDED
```


## Latest orchestrator logs

```
Showing: /home/pudding/Projects/VelaNova/logs/voice_loop-20250924.log
2025-09-24 06:25:53,279 [INFO] boot {"log_file": "/home/pudding/Projects/VelaNova/logs/voice_loop-20250924.log", "time": "2025-09-24T06:25:53"}
2025-09-24 06:25:53,280 [WARNING] forcing_soft_wake {'engine': 'soft'}
2025-09-24 06:25:53,280 [WARNING] forcing_stt_cpu {'device': 'cuda', 'env': {'STT_DEVICE': None, 'CTRANSLATE2_DEVICE': None}, 'compute_type': 'int8_float16'}
2025-09-24 06:25:54,530 [INFO] stt_ready {"device": "cpu", "compute_type": "int8", "model": "tiny", "local": false}
2025-09-24 06:25:54,531 [INFO] dev_mode {"enabled": true, "model": "llama3.2-coder:local"}
2025-09-24 06:25:54,538 [INFO] memory_doc {"doc_id": "ed12390582014723899f6e9892e6a12f"}
2025-09-24 06:25:54,539 [INFO] loop_start {"wake_phrases": ["velanova", "hey velanova", "hey nova"], "stop_phrase": "sleep nova"}
2025-09-24 06:25:54,539 [INFO] await_wake {"mode": "text"}
```


## settings.yaml snapshot (keys only, redacted)

```
# V2 — Phase C/D: live mic + hard/soft wake, Whisper (CUDA), Piper (local), and durable local memory (SQLite)
# Notes:
# - Hard-wake uses *.onnx models in /home/pudding/Projects/VelaNova/models/wake/
# - "hey jarvis"/"hey mycroft"/"alexa" are hard-wake (KWS); "velanova" variants are soft-wake (STT fallback).
# - Mic uses system default (index -1) so Pulse/PipeWire handle 48k↔16k reliably.
# - Phase D uses a local SQLite DB under ~/Projects/VelaNova/memory/db/memory.sqlite.

version: 2

wake:
  engine: soft
  mode: text
  model_dir: /home/pudding/Projects/VelaNova/models/wake
  model_glob: "*.onnx"
  sensitivity: 0.48
  min_silence_ms: 600
  trigger_debounce_ms: 1500
  phrases:
    # Hard-wake (requires matching .onnx models)
    - hey jarvis
    - hey mycroft
    - alexa
    # Soft-wake (phrase-checked by STT)
    - velanova
    - hey velanova
  stop_phrase: "sleep nova"

stt:
  engine: soft
  mode: text
  impl: faster-whisper
  model: small
  device: cuda                # cuda | cpu
  compute_type: int8_float16
  beam_size: 1
  sample_rate: 16000
  vad:
    enable: true
    method: webrtc
    max_silence_ms: 900
  chunk_ms: 2048

tts:
  engine: soft
  mode: text
  voice: en_GB-cori-high
  voice_path: /home/pudding/Projects/VelaNova/models/piper/en/en_GB/cori/high/en_GB-cori-high.onnx
  config_path: /home/pudding/Projects/VelaNova/models/piper/en/en_GB/cori/high/en_GB-cori-high.onnx.json
  sample_rate: 22050
  rate: 1.00
  volume: 1.00
  length_scale: 1.00
  noise_scale: 0.667
  temp_wav: /home/pudding/Projects/VelaNova/logs/last_output.wav

llm:
  provider: ollama
  endpoint: http://localhost:11434
  model: llama3.2:3b
  options:
    num_ctx: 4096
    temperature: 0.5
    max_tokens: 256
  system_prompt: |
    You are VelaNova. Be concise and clear when speaking responses aloud.


dev:
  enabled: true
  coder_model: llama3.2-coder:local
# === Phase D: Durable Memory (local only) ===
memory:
  engine: sqlite
  path: /home/pudding/Projects/VelaNova/memory/db/memory.sqlite
  recall:
    k: 5
  retention:
    max_turns: 5000
    prune_on_start: false
  logging:
    enabled: true

orchestrator:
  input_device_index: -1
  output_device_index: -1
  max_turn_seconds: 45
  listen_timeout_seconds: 12
  grace_after_tts_ms: 300
  mode: text

logging:
  file: /home/pudding/Projects/VelaNova/logs/voice_loop-%Y%m%d.log
  level: INFO
  rotate_days: 7

# Guardrails
connected:
  enabled: false

security:
  egress_block_expected: true
```


## Summary checklist

- [ ] All containers healthy (docker compose ps)
- [ ] Wake word active (no false triggers in quiet room)
- [ ] STT on GPU (faster-whisper) confirmed in logs
- [ ] TTS voice OK (Piper running, voice selected)
- [ ] LLM models present in Ollama (deepseek-r1:7b, qwen2.5-coder:7b)
- [ ] Orchestrator round-trip < 2.5s median
- [ ] Memory DB directory present (.chroma)
